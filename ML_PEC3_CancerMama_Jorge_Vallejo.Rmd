---
title: "Cáncer de mama"
subtitle: "Machine Learning - PEC 3"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
  number_sections: true
header-includes:
  - \renewcommand{\contentsname}{Sumario}
toc: true
# Next code for knitting more than one type of document automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
                    output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

#bibliography: scholar.bib
---
  
```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center",
                      cache = TRUE)
```

```{r libraries, include=FALSE}
# Load packages
library(knitr)
```

```{r create directory structure, results='hide'}
# directories <- c("data", "results", "intermediateData")
directories <- c("results/", "intermediateData/")

# Create directories
sapply(directories[!(dir.exists(directories))], # Directories that doesn't exist
       dir.create) # Create those directories
```

```{r delete results files, eval= FALSE}
# Run this chunk ONLY if you want to re-do
# all the report FROM ZERO.
# Remember that the .RData files are there to
# avoid unnecesarily redoing long data processing.

file.remove(
  # Create a character vector of relative paths
  # to all files in the variable directories
  list.files(path = directories,
           all.files = TRUE,
           full.names = TRUE,
           recursive = TRUE)
)
```

```{r functions}
# This chunk is for user defined functions

##########################
# Find the span of a range
# From https://r.789695.n4.nabble.com/Calculate-Range-td4680579.html
range_span <- function(x, na.rm=TRUE) return(diff(range(x)))


##########################
# Draw a boxplot with log-distanced ticks
# Adapted from code I found in StackOverflow (but I can't find the url anymore)
log_boxplot <- function(x, ...){
  # To avoid problems with the logarithm of 0, let's change the value 0 by value 1.
  # x[x == 0] <- 1

  boxplot(x,
        log = "y",
        yaxt = "n",  # Do not draw ticks in y axis.
        ...) # Additional arguments to be passed to the function boxplot.

# Establishes limits for y axis and, from base 10 logarithm,
# max and min values of the dataframe.
  y1 <- floor(log10(range(x, na.rm = TRUE))) 
# Vector with integer values from minimum to maximum for the axis.
  pow <- seq(y1[1], y1[2]+1)
# Vector with ticks' positions.
  ticksat <- as.vector(sapply(pow, function(p) (1:10)*10^p))
# Drawing the axis (main ticks)
  axis(2, 10^pow, labels = formatC(10^pow, digits = 0, format = "d"),
       gap.axis = 0.5)
# Drawing the axis (secondary ticks)
  axis(2, ticksat, labels = NA, tcl = -0.25, lwd = 0, lwd.ticks = 1)
}
```


\newpage

# Análisis exploratorio
```{r check the existence of data file in data folder}

# The file with the dataset must be in a directory called "data"
# placed in the same directory of the code we are going to run

if (! dir.exists("./data")) {
  stop("El directorio ./data no existe.
       El dataset debe estar en el directorio ./data para generar el reporte.")
}

# Check how many files (if any) are in data directory with format csv
csv_files <- list.files(path = "./data", pattern = "csv")

if (length(csv_files) < 1){
  stop("No se ha encontrado en el directorio './data'
       ningún archivo con extensión csv.
       Para el uso de este informe automático es necesario
       que el dataset esté en forma de fichero csv (y con extensión '.csv')
       en el directorio '.data/'")
}else if (length(csv_files) > 1){
  stop("Demasiados archivos con extensión '.csv' en el directorio './data'.
       Para el uso de este informe automático es necesario 
       que el dataset esté en forma de un único fichero csv 
       (y con extensión '.csv') en el directorio '.data/'")
}

```

El set de datos para este informe proviene del fichero "`r csv_files`".

```{r structure of the data}
# Read dataset into a data frame and check its structure
raw_dataframe <- read.csv(
  file.path("data", csv_files),
  stringsAsFactors = TRUE)

observaciones <- nrow(raw_dataframe)
variables <- ncol(raw_dataframe)
# Number of levels in the last column of the dataframe
diag_levels <- levels(raw_dataframe[, ncol(raw_dataframe)])
clases <- length(diag_levels)

```

El dataset está compuesto por:  
**`r format(observaciones, big.mark = " ")` observaciones**, de cada una de las cuales se han medido  
**`r variables` variables**.

El conjunto de observaciones está dividido en **`r clases` clases**: `r diag_levels`.

La distribución de cada clase es la siguiente:

```{r}
kable(table(raw_dataframe[, ncol(raw_dataframe)]),
      col.names = c("Clase", "Frecuencia"),
      align = c('c','l'),
      format.args = list(big.mark = " "))
```

## Muestra de los datos de las diferentes variables
```{r variables}
str(raw_dataframe,
    vec.len = 2)
```
\newpage

## Tipos de variables
```{r class of variables, fig.align='left'}
knitr::kable(table(unlist(lapply(raw_dataframe, class))),
             col.names = c("Clase", "Frecuencia"),
             caption = '')
```

## Otras características de interés
```{r NAs y rangos en una tabla}
# Data frame except first and last columns
raw_dataframe_num <- raw_dataframe[, -c(1, # all columns except the first
                                        ncol(raw_dataframe))] # and last

# Rangos de variable
rangos_variable <- apply(raw_dataframe_num,
                         2,
                         range, na.rm = TRUE)

# Extensiones de rango
ex_ra <- apply(
    raw_dataframe_num,
2,
range_span,
na.rm = TRUE)

# Variables with largest and tiniest ranges
r_l <- which(ex_ra == max(ex_ra))
r_t <- which(ex_ra == min(ex_ra))

knitr::kable(cbind(
c("Valores perdidos (NAs)", "Variable de mayor rango", "Variable de menor rango"),
c(sum(is.na(raw_dataframe)), # total NAs in data frame
  # Maximum range in variables
  paste0(colnames(raw_dataframe_num)[r_l],
         " (", rangos_variable[, r_l][1], " - ",rangos_variable[, r_l][2], " )"),
# Minimum range in variables
paste0(colnames(raw_dataframe_num)[r_t],
       " (", rangos_variable[, r_t][1], " - ",rangos_variable[, r_t][2], " )")
)),
align = 'rl')

# Desviaciones típicas de las variables
 variables_sd <- apply(raw_dataframe_num, 2, sd)
```
## Distribución de rangos entre las variables

```{r calcula la extensión del rango de cada variable}
ex_ra_ben <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "B", ],
                   2, range_span)
ex_ra_mal <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "M", ],
                   2, range_span)

```

```{r calcula la desviación típica de cada variable, eval=FALSE}
sd_ben <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "B", ],
                   2, sd)
sd_mal <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "M", ],
                   2, sd)
```

```{r variable ranges boxplot, fig.height=6, fig.width=5}
# par(mfcol = c(1, 2))
log_boxplot(list(ex_ra_ben, ex_ra_mal),
            main = "Distribución de la extensión\n de rangos en las variables",
            names = c("Benigno", "Maligno"),
            ylab = "Tamaño del rango",
            col = c("aliceblue", "lightgoldenrod1"))

# log_boxplot(list(sd_ben, sd_mal),
#             main = "Distribución de la desviación\n típica en las variables",
#             names = c("Benigno", "Maligno"),
#             ylab = "Tamaño del rango",
#             col = c("aliceblue", "lightgoldenrod1"))
```



# Predicción mediante k-Nearest Neighbour
El algoritmo k-NN es sensible a diferencias en el tamaño de los rangos de las diferentes variables numéricas. Para evitar que estas diferencias introduzcan un sesgo en la clasificación modificaremos los datos de las variables como parte del pre-procesado. En este caso en concreto hemos usado la **estandarización por z-score**. Hemos de ser conscientes que, al utilizar este método, de estandarización estamos asumiendo que los datos sobre los que usaremos el algoritmo en el futuro tendrán la misma media y desviación estándar que el set de datos que usamos como entrenamiento.

```{r z score stardardization}

```


