---
title: "Cáncer de mama"
subtitle: "Machine Learning - PEC 3"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
  number_sections: true
header-includes:
  - \renewcommand{\contentsname}{Sumario}
toc: true
# Next code for knitting more than one type of document automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
                    output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

#bibliography: scholar.bib
---
  
```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center",
                      cache = TRUE)
```

```{r libraries, include=FALSE}
# Load packages
library(knitr)
```

```{r create directory structure, results='hide'}
# directories <- c("data", "results", "intermediateData")
directories <- c("results/", "intermediateData/")

# Create directories
sapply(directories[!(dir.exists(directories))], # Directories that doesn't exist
       dir.create) # Create those directories
```

```{r delete results files, eval= FALSE}
# Run this chunk ONLY if you want to re-do
# all the report FROM ZERO.
# Remember that the .RData files are there to
# avoid unnecesarily redoing long data processing.

file.remove(
  # Create a character vector of relative paths
  # to all files in the variable directories
  list.files(path = directories,
           all.files = TRUE,
           full.names = TRUE,
           recursive = TRUE)
)
```

```{r functions}
# This chunk is for user defined functions

##########################
# Find the span of a range
# From https://r.789695.n4.nabble.com/Calculate-Range-td4680579.html
range_span <- function(x, na.rm=TRUE) return(diff(range(x)))


##########################
# Draw a boxplot with log-distanced ticks
# Adapted from code I found in StackOverflow (but I can't find the url anymore)
log_boxplot <- function(x, ...){
  # To avoid problems with the logarithm of 0, let's change the value 0 by value 1.
  # x[x == 0] <- 1

  boxplot(x,
        log = "y",
        yaxt = "n",  # Do not draw ticks in y axis.
        ...) # Additional arguments to be passed to the function boxplot.

# Establishes limits for y axis and, from base 10 logarithm,
# max and min values of the dataframe.
  y1 <- floor(log10(range(x, na.rm = TRUE))) 
# Vector with integer values from minimum to maximum for the axis.
  pow <- seq(y1[1], y1[2]+1)
# Vector with ticks' positions.
  ticksat <- as.vector(sapply(pow, function(p) (1:10)*10^p))
# Drawing the axis (main ticks)
  axis(2, 10^pow, labels = formatC(10^pow, digits = 0, format = "d"),
       gap.axis = 0.5)
# Drawing the axis (secondary ticks)
  axis(2, ticksat, labels = NA, tcl = -0.25, lwd = 0, lwd.ticks = 1)
}
```


\newpage

# Análisis exploratorio
```{r check the existence of data file in data folder}

# The file with the dataset must be in a directory called "data"
# placed in the same directory of the code we are going to run

if (! dir.exists("./data")) {
  stop("El directorio ./data no existe.
       El dataset debe estar en el directorio ./data para generar el reporte.")
}

# Check how many files (if any) are in data directory with format csv
csv_files <- list.files(path = "./data", pattern = "csv")

if (length(csv_files) < 1){
  stop("No se ha encontrado en el directorio './data'
       ningún archivo con extensión csv.
       Para el uso de este informe automático es necesario
       que el dataset esté en forma de fichero csv (y con extensión '.csv')
       en el directorio '.data/'")
}else if (length(csv_files) > 1){
  stop("Demasiados archivos con extensión '.csv' en el directorio './data'.
       Para el uso de este informe automático es necesario 
       que el dataset esté en forma de un único fichero csv 
       (y con extensión '.csv') en el directorio '.data/'")
}

```

El set de datos para este informe proviene del fichero "`r csv_files`".

```{r structure of the data}
# Read dataset into a data frame and check its structure
raw_dataframe <- read.csv(
  file.path("data", csv_files),
  stringsAsFactors = TRUE)

observaciones <- nrow(raw_dataframe)
variables <- ncol(raw_dataframe)
# Number of levels in the last column of the dataframe
diag_levels <- levels(raw_dataframe[, ncol(raw_dataframe)])
clases <- length(diag_levels)

```

El dataset está compuesto por:  
**`r format(observaciones, big.mark = " ")` observaciones**, de cada una de las cuales se han medido  
**`r variables` variables**.

El conjunto de observaciones está dividido en **`r clases` clases**: `r diag_levels`.

La distribución de cada clase es la siguiente:

```{r}
kable(table(raw_dataframe[, ncol(raw_dataframe)]),
      col.names = c("Clase", "Frecuencia"),
      align = c('c','l'),
      format.args = list(big.mark = " "))
```

## Muestra de los datos de las diferentes variables
```{r variables}
str(raw_dataframe,
    vec.len = 2)
```
\newpage

## Tipos de variables
```{r class of variables, fig.align='left'}
knitr::kable(table(unlist(lapply(raw_dataframe, class))),
             col.names = c("Clase", "Frecuencia"),
             caption = '')
```

## Otras características de interés
```{r NAs y rangos en una tabla}
# Data frame except first and last columns
raw_dataframe_num <- raw_dataframe[, -c(1, # all columns except the first
                                        ncol(raw_dataframe))] # and last

# Rangos de variable
rangos_variable <- apply(raw_dataframe_num,
                         2,
                         range, na.rm = TRUE)

# Extensiones de rango
ex_ra <- apply(
    raw_dataframe_num,
2,
range_span,
na.rm = TRUE)

# Variables with largest and tiniest ranges
r_l <- which(ex_ra == max(ex_ra))
r_t <- which(ex_ra == min(ex_ra))

knitr::kable(cbind(
c("Valores perdidos (NAs)", "Variable de mayor rango", "Variable de menor rango"),
c(sum(is.na(raw_dataframe)), # total NAs in data frame
  # Maximum range in variables
  paste0(colnames(raw_dataframe_num)[r_l],
         " (", rangos_variable[, r_l][1], " - ",rangos_variable[, r_l][2], " )"),
# Minimum range in variables
paste0(colnames(raw_dataframe_num)[r_t],
       " (", rangos_variable[, r_t][1], " - ",rangos_variable[, r_t][2], " )")
)),
align = 'rl')

# Desviaciones típicas de las variables
 variables_sd <- apply(raw_dataframe_num, 2, sd)
```
## Distribución de rangos entre las variables

```{r calcula la extensión del rango de cada variable}
ex_ra_ben <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "B", ],
                   2, range_span)
ex_ra_mal <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "M", ],
                   2, range_span)

```

```{r calcula la desviación típica de cada variable, eval=FALSE}
sd_ben <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "B", ],
                   2, sd)
sd_mal <- apply(raw_dataframe_num[raw_dataframe$diagnosis == "M", ],
                   2, sd)
```

```{r variable ranges boxplot, fig.height=6, fig.width=5, out.width='50%', fig.cap='La extensión de los rangos varía mucho de unas variables a otras, pero su distribución es comparable entre los dos diagnósticos (benigno y maligno).'}
# par(mfcol = c(1, 2))
log_boxplot(list(ex_ra_ben, ex_ra_mal),
            main = "Distribución de la extensión\n de rangos en las variables",
            names = c("Benigno", "Maligno"),
            ylab = "Tamaño del rango",
            col = c("aliceblue", "lightgoldenrod1"))

# log_boxplot(list(sd_ben, sd_mal),
#             main = "Distribución de la desviación\n típica en las variables",
#             names = c("Benigno", "Maligno"),
#             ylab = "Tamaño del rango",
#             col = c("aliceblue", "lightgoldenrod1"))
```

## Pre-procesado

```{r separa sets entrenamiento y prueba}
library(caret)
# Observations by subset
training_ratio <- 0.67 # Ratio of samples in the training subset

set.seed(12345)
# Reordered row numbers
training_rows <- createDataPartition(raw_dataframe$diagnosis, p = training_ratio,
                                     list = FALSE)
# Subset the dataframe
training_dataframe <- raw_dataframe[training_rows, ]
test_dataframe <- raw_dataframe[-training_rows, ]
```

Antes de analizar el set de datos con los algoritmos de aprendizaje automático, primero es necesario  repartir los datos para generar grupos de entrenamiento y de evaluación. En esta caso he decidido dividr el set al azar en un grupo de entrenamiento (`r paste0(training_ratio * 100, "%")` de las observaciones), y un grupo de evaluación ((`r paste0((1-training_ratio) * 100, "%")` de las observaciones).

El muestreo para formar los grupos está estratificado por la variable _diganosis_, para mantener la misma proporción de diagnósticos tanto en el grupo de entrenamiento como en el de evaluación.

```{r tabla resumen sets}
train <- nrow(training_dataframe)
test <- nrow(test_dataframe)

resumen <- data.frame(
  cbind(
  # Sizes of subsets
  c(train,# Training size
  test), # Test size
  # Ratio of benign diagnosis each subset
  c(sum(training_dataframe$diagnosis == "B") / train,
    sum(test_dataframe$diagnosis == "B") / test),
  # Ratio of malign diagnosis each subset
  c(sum(training_dataframe$diagnosis == "M") / train,
    sum(test_dataframe$diagnosis == "M") / test)),
  row.names = c("Entrenamiento", "Evaluación")
)

# Design table
knitr::kable(resumen,
             col.names = c("Observaciones", "Ratio benigno", "Ratio maligno"),
             format.args = list(digits = 2),
             align = 'c',
             caption = 'Comparación entre los sets de entrenamiento y evaluación de los siguientes elementos: observaciones, tasa de observaciones con diagnóstico benigno, y tasa de observaciones con diagnóstico maligno.'
)


```
\newpage

# Predicción mediante k-Nearest Neighbour
## Estandarización de los datos
El algoritmo k-NN es sensible a diferencias en el tamaño de los rangos de las diferentes variables numéricas. Para evitar que estas diferencias introduzcan un sesgo en la clasificación modificaremos los datos de las variables como parte del pre-procesado. En este caso en concreto hemos usado la **estandarización por z-score**. Hemos de ser conscientes que, al utilizar este método, de estandarización estamos asumiendo que los datos sobre los que usaremos el algoritmo en el futuro tendrán la misma media y desviación estándar que el set de datos que usamos como entrenamiento.

```{r z score stardardization}
z_dataframe <- predict(
  preProcess(raw_dataframe_num, method = c("center","scale")), # "learning" to transform
  raw_dataframe) # data to be transformed
             
```

```{r calcula la extensión del rango de cada variable tras z-score}
ex_ra_benz <- apply(z_dataframe[z_dataframe$diagnosis == "B", -c(1, ncol(z_dataframe))],
                   2, range_span)
ex_ra_malz <- apply(z_dataframe[z_dataframe$diagnosis == "M", -c(1, ncol(z_dataframe))],
                   2, range_span)

```

```{r variable ranges boxplot after z-score, fig.height=6, fig.width=5, out.width='50%', fig.cap='Tras la estandarización mediante z-score la extensión de los rangos es mucho más homogénea entre las variables.'}
log_boxplot(list(ex_ra_ben, ex_ra_mal,
                 ex_ra_benz, ex_ra_malz),
            main = "Distribución de la extensión\n de rangos en las variables",
            names = rep(c("Benigno", "Maligno"), 2),
            ylab = "Tamaño del rango",
            col = c(rep("aliceblue", 2), rep("lightgoldenrod1", 2)))
# Legend
legend("topright", # Position of the legend in the graph
       legend = c("Datos brutos", "Datos estandarizados"),
       fill = c("aliceblue", "lightgoldenrod1"), # Colors of the boxes
       border = NA, # Do not draw a box around the colors
       bty = 'n', # Do not draw a box around the legend
       cex = 0.75) # Size of the characters


```

## Entrenamiento del clasificador kNN
Para entrenar el algoritmo k-NN he usado el subset de datos de entrenamiento, que será remuestreado a su vez mediante el método de validación cruzada de 10 iteraciones.

Para afinar el modelo he usado la función `trainControl()` del paquete de R `caret`.

He elegido el área bajo la curva ROC (AUC, por sus siglas en inglés) como métrica para elegir el modelo óptimo, ya que ofrece un equilibrio entre la capacidad de detectar positivos auténticos, y la de evitar falsos positivos.

```{r entrenamiento knn}
# Subset de entrenamiento (datos estandarizados)
training_z_score <- z_dataframe[training_rows, -1]

set.seed(2020617119)
# Training parameters
train_knn <- trainControl(method = 'repeatedcv', 
                          number = 10, # number of folds
                          summaryFunction = multiClassSummary, # Computes AUC
                          classProbs = TRUE)

# Fit predictive model over tuning paremeters
fit_knn <- caret::train(diagnosis ~ ., # formula diagnosis = predictors (linear)
                        data = training_z_score,
                        method = 'knn',
                        trControl = train_knn,
                        metric = 'AUC', # Metric for the optimal model
                        tuneLength = 10) # Levels of tuning parameter (k)
```

## Modelo óptimo para el algoritmo k-NN
Como podemos ver en la tabla, según el set de datos de entrenamiento que hemos aportado al logaritmo, **el modelo con la mejor puntuación UAC es el que tiene en cuenta los `r fit_knn$bestTune[[1]]` vecinos más cercanos**.

```{r create dataframe with evaluation values, results='asis'}
# Recupera los parametros de interes
kable(knn_evaluation <- fit_knn$results[c(1, 3)],
      format.args = list(digits = 4),
      caption = 'Valores AUC según el número k de vecinos cercanos; calculado para el set de datos de entrenamiento.')

```



\newpage

# Apéndice A: Código

El documento original en formato .Rmd, que incluye el código completo en lenguaje R usado para generar este informe, se puede consultar y descargar en el siguiente repositorio de Github:
[jorgevallejo/breast_cancer_PEC3](https://github.com/jorgevallejo/breast_cancer_PEC3)

# Apéndice B: Reproducibilidad
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
sessionInfo() # For better reproducibility
```

# Apéndice C: Nota para el profesor

No me he equivocado de archivo, esto es lo único que me ha dado tiempo a terminar. Lo he entregado incompleto para que por lo menos no se un 'no presentado'.